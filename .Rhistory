breaks=30, main = '', col = 'darkgrey',
cex = 2,
cex.lab=1.5, cex.axis=1.5,
ylab = 'density',
xlab = 'normalized travel time',
yaxs = 'i',
xaxs = 'i',
xlim = c(-5,10),
ylim = c(0,0.4))]
x = seq(-5, 5, 0.1)
lines(x, dnorm(x, 0,1), col  = 'blue', lwd=4,lty=1)
lines(x, dnorm(x, 0, res$res.sd), col  = 'black', lwd=4, lty=1)
std.q = round(qnorm(0.975)*c(-1,1),2)
v.q = round(qnorm(0.975, 0, v)*c(-1,1),2)
abline(v = std.q, lty=2, lwd = 2, col = 'blue')
abline(v = v.q, lty=2, lwd = 2, col = 'black')
emp.q = B[, quantile((obstt-tt)/sd, c(0.025, 0.975))]
abline(v = emp.q, lty =2, lwd =2, col =  ' darkgrey')
legend( 'topright',
legend = c('N(0,1)', 'N(0,v)', 'N(0,1) 95% PI', 'N(0,v) 95% PI', '95% emp. CI'),
cex = 1.4, lwd = 4,
lty = c(1,1,2,2,2),
title = til,
col = c('blue', 'black', 'blue', 'black', 'darkgrey')
)
}
residual_variance<-function(db, rho, samp = NULL){
if(!is.null(samp)){
A = db[trip %in% samp][order(trip, time)]
}else{
A = db[order(trip, time)]
}
B = A[, param_zeta(time[1], rho, linkId.from, linkId.to, length), by = trip]
D = merge(B, A[, .(obstt= sum(tt)), trip])
D[, res := (obstt - tt)/sd]
list(db = D, res.sd = sd(D$res))
}
numerical_res<-function(tt, est, sym.q){
list(
MAREgeo = 100*exp(mean(log(abs(tt - est)/tt))),
RMSE = sqrt(mean((tt - est)^2)),
MAE  = mean(abs(tt - est)),
ME  = mean(tt- est),
MAPE = 100*mean(abs(tt - est)/tt),
emprical.cov = 100*mean(abs(tt-est)<=sym.q),
PI.length = mean(2*sym.q),
PI.rel.length = 100*mean(2*sym.q/tt)
)
}
M = 1000
set.seed(12345)
# We select 2500 trips which occured in the morning
samp_AM = sample_time_bins_Sumo(2500, 'MR')
# We make sure these trips won't be in the test set
samp_AM = setdiff(samp_AM, test.trips.Sumo)
# We select 1000 trips
samp_AM = sample(samp_AM, M)
# We get the autocorrelation per trip
r = get_rho(samp_AM)
# We get the mean of r
rho = round(mean(r), 2)
print("This is the mean of the autocorrelation")
rho
# We calculate the residuals.
res  = residual_variance(train, rho, samp_AM)
# This is the mean of the residuals obtained for all the observations of the train data.
v = res$res.sd
print("This is the mean of the residuals")
v
# We take trips from the test set that occured in the morning
testAM = test[, timeBins[1], trip][V1 =='MR', trip]
# We apply the method on the test data
A = test[trip %in% testAM, param_zeta(time[1], rho, linkId.from, linkId.to, length), by = trip]
# We merge to be able to get the observed travel time, the real travel time, and the variance
B = merge(test[, .(obstt = sum(tt)), trip], A)
# We get the results using the mean of the residuals v
print("Model estimation using V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975)*v)]))
# We get the results without using v
print("Model estimation without V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975))]))
}
test_method <- predict.traveltime(train, test, 2)
get_rho<-function(samp= NULL){
if(is.null(samp)){
tt = train
xx = tt[, .I[.N>10],by = trip]
}else{
tt = train[trip %in% samp]
xx = tt[trip %in% samp, .I[.N>10],by = trip]
}
rho = tt[xx$V1][,    drop((acf((1/speed - mean)/(sd+1e-5), plot=FALSE, lag.max=5))[[1]]), by = trip]
# We then remove the first autocorrelation from each trip (trip) since it is 100% using this line of code.
a = rho[, V1[2] ,by = trip][, V1]
a
}
get_rho<-function(samp= NULL){
if(is.null(samp)){
tt = train
xx = tt[, .I[.N>10],by = trip]
}else{
tt = train[trip %in% samp]
xx = tt[trip %in% samp, .I[.N>10],by = trip]
}
rho = tt[xx$V1][,    drop((acf((1/speed - mean)/(sd+1e-5), plot=FALSE, lag.max=5))[[1]]), by = trip]
# We then remove the first autocorrelation from each trip (trip) since it is 100% using this line of code.
a = rho[, V1[2] ,by = trip][, V1]
a
}
param_zeta<-function(t0, rho,linkfrom, linkto, len, sequence = FALSE){
rules = list(
#list(start='7:00', end= '10:00', days = 0:6, tag='MR'),
#list(start='12:00', end='15:00', days = 0:6, tag='NR'),
#list(start='17:00', end= '20:00', days = 0:6, tag='ER')
list(start='6:30', end= '9:00', days = 0:6, tag='MR'),
list(start='15:00', end= '18:00', days = 0:6, tag='ER')
)
t0 = as.POSIXlt(t0)
time_bins <- rules2timebins(rules)
tbin = time_bins(t0)
g = graph.stat.full[linkId.from %in% linkfrom]
t = 0                               # time (mean)
vcumlative = 0                                 # variance
vprev = 1
lenprev = 1
if(sequence){
t.seq = v.seq = numeric(length(len))
}
for(i  in 1:(length(len) - 1)){
##for(i in 1:81){
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
t = t + len[i]*d$mean
tbin = time_bins(t0 + t)
vcumlative = vcumlative + len[i]^2  * d$sd^2  + 2*rho* len[i]*lenprev * d$sd * vprev
vprev = d$sd
lenprev = len[i]
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
}
## last linkId.to is NA
i = i+1
if(is.na(linkto[i])){
d = g[linkId.from == linkfrom[i] & timeBins == tbin & is.na(linkId.to)]
}else{
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
}
t = t + len[i]*d$mean
vcumlative = vcumlative + len[i]^2 * d$sd^2 + 2* rho * len[i]*lenprev *d$sd *vprev
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
s = sqrt(vcumlative)
if(sequence){
list(tt =t, sd = s, v.seq = sqrt(v.seq), t.seq = t.seq)
}else{
list(tt =t, sd = s)
}
}
hist_trips<-function(db, til = ''){
B[, hist((obstt - tt)/sd, freq=FALSE,
breaks=30, main = '', col = 'darkgrey',
cex = 2,
cex.lab=1.5, cex.axis=1.5,
ylab = 'density',
xlab = 'normalized travel time',
yaxs = 'i',
xaxs = 'i',
xlim = c(-5,10),
ylim = c(0,0.4))]
x = seq(-5, 5, 0.1)
lines(x, dnorm(x, 0,1), col  = 'blue', lwd=4,lty=1)
lines(x, dnorm(x, 0, res$res.sd), col  = 'black', lwd=4, lty=1)
std.q = round(qnorm(0.975)*c(-1,1),2)
v.q = round(qnorm(0.975, 0, v)*c(-1,1),2)
abline(v = std.q, lty=2, lwd = 2, col = 'blue')
abline(v = v.q, lty=2, lwd = 2, col = 'black')
emp.q = B[, quantile((obstt-tt)/sd, c(0.025, 0.975))]
abline(v = emp.q, lty =2, lwd =2, col =  ' darkgrey')
legend( 'topright',
legend = c('N(0,1)', 'N(0,v)', 'N(0,1) 95% PI', 'N(0,v) 95% PI', '95% emp. CI'),
cex = 1.4, lwd = 4,
lty = c(1,1,2,2,2),
title = til,
col = c('blue', 'black', 'blue', 'black', 'darkgrey')
)
}
residual_variance<-function(db, rho, samp = NULL){
if(!is.null(samp)){
A = db[trip %in% samp][order(trip, time)]
}else{
A = db[order(trip, time)]
}
B = A[, param_zeta(time[1], rho, linkId.from, linkId.to, length), by = trip]
D = merge(B, A[, .(obstt= sum(tt)), trip])
D[, res := (obstt - tt)/sd]
list(db = D, res.sd = sd(D$res))
}
numerical_res<-function(tt, est, sym.q){
list(
MAREgeo = 100*exp(mean(log(abs(tt - est)/tt))),
RMSE = sqrt(mean((tt - est)^2)),
MAE  = mean(abs(tt - est)),
ME  = mean(tt- est),
MAPE = 100*mean(abs(tt - est)/tt),
emprical.cov = 100*mean(abs(tt-est)<=sym.q),
PI.length = mean(2*sym.q),
PI.rel.length = 100*mean(2*sym.q/tt)
)
}
test_method <- predict.traveltime(train, test, 2)
predict.traveltime <- function(train, test, l){
train[, linkId.from := linkId, by = trip]
train[, linkId.to := shift(linkId, type = 'lead'), by = trip]
train[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
test[, linkId.from := linkId, by = trip]
test[, linkId.to := shift(linkId, type = 'lead'), by = trip]
test[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
L = l  # minimum number of observatinos
graph.stat = train[, .(mu = mean(1/speed),  sd2 = var(1/speed), N=N[1]) ,by = list(linkId.from, linkId.to, timeBins)]
full.graph = graph.stat[, .(timeBins = c('Other', 'MR', 'ER')) ,by = list(linkId.from, linkId.to)]
graph.stat = merge(full.graph, graph.stat, by= c('linkId.from', 'linkId.to', 'timeBins'), all.x = TRUE)
graph.stat$N[is.na(graph.stat$N)]<-0
graph.stat.from.tb = train[, .(mu = mean(1/speed),
sd2 = var(1/speed), N= .N) ,
by = list(linkId.from, timeBins)]
graph.stat.tb = train[, .(mu = mean(1/speed),
sd2 = var(1/speed), N= .N) ,by = list(timeBins)]
graph.stat.full =  merge(graph.stat,
graph.stat.from.tb[N>L, .(mu.from.tb = mu,
sd2.from.tb = sd2, linkId.from, timeBins)],
all.x = TRUE,
by.x=c('linkId.from', 'timeBins'),
by.y = c('linkId.from', 'timeBins'))
graph.stat.full =  merge(graph.stat.full,
graph.stat.tb[N>L, .(mu.tb = mu, sd2.tb = sd2, timeBins)],
all.x = TRUE, by.x=c('timeBins'), by.y = c('timeBins'))
graph.stat.full[, muspeed := ifelse(is.na(mu) | N < L, ifelse(is.na(mu.from.tb), mu.tb, mu.from.tb), mu)]
graph.stat.full[,  imputed_mean := ifelse(muspeed== mu, FALSE, TRUE )]
graph.stat.full[, sdspeed := ifelse(is.na(sd2), ifelse(is.na(sd2.from.tb), sd2.tb, sd2.from.tb), sd2)]
graph.stat.full[, imputed_sd := ifelse(sdspeed == sd2  & !is.na(sd2) , FALSE, TRUE)]
graph.stat.full = graph.stat.full[,.(linkId.from,
linkId.to,
timeBins,
mean = muspeed,
sd = sqrt(sdspeed),
imputed_sd,
imputed_mean )]
train = merge(train, graph.stat.full, all.x = TRUE, by = c('linkId.from', 'linkId.to', 'timeBins'), sort = FALSE)[order(trip,time)]
M = 1000
set.seed(12345)
# We select 2500 trips which occured in the morning
samp_AM = sample_time_bins_Sumo(2500, 'MR')
# We make sure these trips won't be in the test set
samp_AM = setdiff(samp_AM, test.trips.Sumo)
# We select 1000 trips
samp_AM = sample(samp_AM, M)
# We get the autocorrelation per trip
r = get_rho(samp_AM)
# We get the mean of r
rho = round(mean(r), 2)
print("This is the mean of the autocorrelation")
rho
# We calculate the residuals.
res  = residual_variance(train, rho, samp_AM)
# This is the mean of the residuals obtained for all the observations of the train data.
v = res$res.sd
print("This is the mean of the residuals")
v
# We take trips from the test set that occured in the morning
testAM = test[, timeBins[1], trip][V1 =='MR', trip]
# We apply the method on the test data
A = test[trip %in% testAM, param_zeta(time[1], rho, linkId.from, linkId.to, length), by = trip]
# We merge to be able to get the observed travel time, the real travel time, and the variance
B = merge(test[, .(obstt = sum(tt)), trip], A)
# We get the results using the mean of the residuals v
print("Model estimation using V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975)*v)]))
# We get the results without using v
print("Model estimation without V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975))]))
}
get_rho<-function(samp= NULL){
if(is.null(samp)){
tt = train
xx = tt[, .I[.N>10],by = trip]
}else{
tt = train[trip %in% samp]
xx = tt[trip %in% samp, .I[.N>10],by = trip]
}
rho = tt[xx$V1][,    drop((acf((1/speed - mean)/(sd+1e-5), plot=FALSE, lag.max=5))[[1]]), by = trip]
# We then remove the first autocorrelation from each trip (trip) since it is 100% using this line of code.
a = rho[, V1[2] ,by = trip][, V1]
a
}
param_zeta<-function(t0, rho,linkfrom, linkto, len, sequence = FALSE){
rules = list(
#list(start='7:00', end= '10:00', days = 0:6, tag='MR'),
#list(start='12:00', end='15:00', days = 0:6, tag='NR'),
#list(start='17:00', end= '20:00', days = 0:6, tag='ER')
list(start='6:30', end= '9:00', days = 0:6, tag='MR'),
list(start='15:00', end= '18:00', days = 0:6, tag='ER')
)
t0 = as.POSIXlt(t0)
time_bins <- rules2timebins(rules)
tbin = time_bins(t0)
g = graph.stat.full[linkId.from %in% linkfrom]
t = 0                               # time (mean)
vcumlative = 0                                 # variance
vprev = 1
lenprev = 1
if(sequence){
t.seq = v.seq = numeric(length(len))
}
for(i  in 1:(length(len) - 1)){
##for(i in 1:81){
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
t = t + len[i]*d$mean
tbin = time_bins(t0 + t)
vcumlative = vcumlative + len[i]^2  * d$sd^2  + 2*rho* len[i]*lenprev * d$sd * vprev
vprev = d$sd
lenprev = len[i]
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
}
## last linkId.to is NA
i = i+1
if(is.na(linkto[i])){
d = g[linkId.from == linkfrom[i] & timeBins == tbin & is.na(linkId.to)]
}else{
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
}
t = t + len[i]*d$mean
vcumlative = vcumlative + len[i]^2 * d$sd^2 + 2* rho * len[i]*lenprev *d$sd *vprev
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
s = sqrt(vcumlative)
if(sequence){
list(tt =t, sd = s, v.seq = sqrt(v.seq), t.seq = t.seq)
}else{
list(tt =t, sd = s)
}
}
hist_trips<-function(db, til = ''){
B[, hist((obstt - tt)/sd, freq=FALSE,
breaks=30, main = '', col = 'darkgrey',
cex = 2,
cex.lab=1.5, cex.axis=1.5,
ylab = 'density',
xlab = 'normalized travel time',
yaxs = 'i',
xaxs = 'i',
xlim = c(-5,10),
ylim = c(0,0.4))]
x = seq(-5, 5, 0.1)
lines(x, dnorm(x, 0,1), col  = 'blue', lwd=4,lty=1)
lines(x, dnorm(x, 0, res$res.sd), col  = 'black', lwd=4, lty=1)
std.q = round(qnorm(0.975)*c(-1,1),2)
v.q = round(qnorm(0.975, 0, v)*c(-1,1),2)
abline(v = std.q, lty=2, lwd = 2, col = 'blue')
abline(v = v.q, lty=2, lwd = 2, col = 'black')
emp.q = B[, quantile((obstt-tt)/sd, c(0.025, 0.975))]
abline(v = emp.q, lty =2, lwd =2, col =  ' darkgrey')
legend( 'topright',
legend = c('N(0,1)', 'N(0,v)', 'N(0,1) 95% PI', 'N(0,v) 95% PI', '95% emp. CI'),
cex = 1.4, lwd = 4,
lty = c(1,1,2,2,2),
title = til,
col = c('blue', 'black', 'blue', 'black', 'darkgrey')
)
}
residual_variance<-function(db, rho, samp = NULL){
if(!is.null(samp)){
A = db[trip %in% samp][order(trip, time)]
}else{
A = db[order(trip, time)]
}
B = A[, param_zeta(time[1], rho, linkId.from, linkId.to, length), by = trip]
D = merge(B, A[, .(obstt= sum(tt)), trip])
D[, res := (obstt - tt)/sd]
list(db = D, res.sd = sd(D$res))
}
numerical_res<-function(tt, est, sym.q){
list(
MAREgeo = 100*exp(mean(log(abs(tt - est)/tt))),
RMSE = sqrt(mean((tt - est)^2)),
MAE  = mean(abs(tt - est)),
ME  = mean(tt- est),
MAPE = 100*mean(abs(tt - est)/tt),
emprical.cov = 100*mean(abs(tt-est)<=sym.q),
PI.length = mean(2*sym.q),
PI.rel.length = 100*mean(2*sym.q/tt)
)
}
test_method <- predict.traveltime(train, test, 2)
View(Sumo_data)
#install.packages("devtools")
#devtools::install_github("melmasri/traveltimeHMM")
library(traveltimeHMM)
library(dplyr)
library(tidyr)
library(data.table)
source('07_Algorithm.R')
install.packages("devtools")
install.packages("roxygen2")
devtools::create("traveltimeCLT")
devtools::create("traveltimeCLT")
devtools::install_github("AdrienHdzAdrienHdz/SUMO_Travel_time_estimation/tree/master/traveltimeCLT")
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/tree/master/traveltimeCLT")
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
#install.packages("devtools")
#devtools::install_github("melmasri/traveltimeHMM")
library(traveltimeHMM)
library(dplyr)
library(tidyr)
library(data.table)
library(traveltimeCLT)
# Loading data
Sumo_data <- read.csv("Quebec_data/Sumo_data.csv")
Sumo_data$speed <- exp(Sumo_data$logspeed)
# Transforming variables
Sumo_data <- as.data.table(Sumo_data)
Sumo_data$timeBins <- as.character(Sumo_data$timeBins)
# Creating test trips
set.seed(2020)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
# Transforming variables
Sumo_data <- as.data.table(Sumo_data)
Sumo_data$timeBins <- as.character(Sumo_data$timeBins)
# Creating test trips
set.seed(2020)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
View(Sumo_data)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 2)
test.trips.Sumo <- traveltimeCLT::create_test_trips(M = 2000, Sumo_data, min.n = 1)
create_test_trips<-function(M = 500, db, min.n = 1){
## Setting the graph
db[, linkId.from := linkId, by = trip]
db[, linkId.to := shift(linkId, type = 'lead'), by = trip]
db[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
A = db[, .(N = N[1]), by =list(linkId.from, linkId.to, timeBins) ]
A[, N.left := 0 ]
setkey(A, linkId.from, linkId.to, timeBins)
bank = c()
unique.trips =db[, min(N>1)  , trip][V1 ==1][, trip]
repeat{
n = length(unique.trips)
car = unique.trips[sample.int(n,1)]
k = db[trip==car, .(linkId.from, linkId.to, timeBins)]
if(A[k, all(N -N.left - 1> 0 )]){
bank = c(bank,car)              ## add the trip
unique.trips = setdiff(unique.trips, bank) ## removing all smapled trips
## updating A
A[k, N.left:= N.left + 1]
## break if number of samples reached
if(length(bank) >=M)
break
}
}
bank
}
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
# Loading data
Sumo_data <- read.csv("Quebec_data/Sumo_data.csv")
library(traveltimeCLT)
library(data.table)
#install.packages("devtools")
#devtools::install_github("melmasri/traveltimeHMM")
library(traveltimeHMM)
library(dplyr)
library(tidyr)
Sumo_data$speed <- exp(Sumo_data$logspeed)
# Transforming variables
Sumo_data <- as.data.table(Sumo_data)
Sumo_data$timeBins <- as.character(Sumo_data$timeBins)
# Creating test trips
set.seed(2020)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
library(traveltimeCLT)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
library(traveltimeCLT)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT", force = TRUE)
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT", force = TRUE)
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.github("https://github.com/AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
install.devtools("https://github.com/AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
install.devtools::("https://github.com/AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
devtools::install_github("https://github.com/AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
library(devtools)
devtools::install_github("AdrienHdz/SUMO_Travel_time_estimation/traveltimeCLT")
devtools::install_github("AdrienHdz/Sumo_Travel_time_estimation/traveltimeCLT")
remove.packages(traveltimeCLT)
remove.packages("traveltimeCLT")
devtools::install_github("AdrienHdz/Sumo_Travel_time_estimation/traveltimeCLT")
devtools:::check()
library(traveltimeCLT)
