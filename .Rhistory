D = merge(B, A[, .(obstt= sum(tt)), trip])
D[, res := (obstt - tt)/sd]
res = list(db = D, res.sd = sd(D$res))
v = res$res.sd
print("This is the mean of the residuals")
print(v)
obj <- list(variance = v, rho = rho)
class(obj) = append(class(obj), "traveltime", after=0)
invisible(obj)
}
predict.traveltimeCLT <- function(obj.traveltime = NULL, data.test = NULL, bin = "MR", rules = myrules){
data.test[, linkId.from := linkId, by = trip]
data.test[, linkId.to := shift(linkId, type = 'lead'), by = trip]
data.test[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
# We take trips from the test set that occured in the morning
samp.test = data.test[, timeBins[1], trip][V1 == bin , trip]
param_zeta<-function(t0, rho,linkfrom, linkto, len, sequence = FALSE){
t0 = as.POSIXlt(t0)
time_bins <- rules2timebins(rules)
tbin = time_bins(t0)
g = obj.traveltime$Graph.stat[linkId.from %in% linkfrom]
t = 0                               # time (mean)
vcumlative = 0                                 # variance
vprev = 1
lenprev = 1
if(sequence){
t.seq = v.seq = numeric(length(len))
}
for(i  in 1:(length(len) - 1)){
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
t = t + len[i]*d$mean
tbin = time_bins(t0 + t)
vcumlative = vcumlative + len[i]^2  * d$sd^2  + 2*rho* len[i]*lenprev * d$sd * vprev
vprev = d$sd
lenprev = len[i]
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
}
## last linkId.to is NA
i = i+1
if(is.na(linkto[i])){
d = g[linkId.from == linkfrom[i] & timeBins == tbin & is.na(linkId.to)]
}else{
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
}
t = t + len[i]*d$mean
vcumlative = vcumlative + len[i]^2 * d$sd^2 + 2* rho * len[i]*lenprev *d$sd *vprev
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
s = sqrt(vcumlative)
if(sequence){
list(tt =t, sd = s, v.seq = sqrt(v.seq), t.seq = t.seq)
}else{
list(tt =t, sd = s)
}}
# We apply the method on the test data
A = data.test[trip %in% samp.test, param_zeta(time[1], obj.traveltime$Rho, linkId.from, linkId.to, length), by = trip]
# We merge to be able to get the observed travel time, the real travel time, and the variance
B = merge(data.test[, .(obstt = sum(tt)), trip], A)
# We get the results using the mean of the residuals v
numerical_res<-function(tt, est, sym.q){
list(
MAREgeo = 100*exp(mean(log(abs(tt - est)/tt))),
RMSE = sqrt(mean((tt - est)^2)),
MAE  = mean(abs(tt - est)),
ME  = mean(tt- est),
MAPE = 100*mean(abs(tt - est)/tt),
emprical.cov = 100*mean(abs(tt-est)<=sym.q),
PI.length = mean(2*sym.q),
PI.rel.length = 100*mean(2*sym.q/tt)
)
}
print("Model estimation using V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975)*obj.traveltime$Variance)]))
# We get the results without using v
print("Model estimation without V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975))]))
}
create_test_trips<-function(M = 500, db, min.n = 1){
## Setting the graph
db[, linkId.from := linkId, by = trip]
db[, linkId.to := shift(linkId, type = 'lead'), by = trip]
db[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
A = db[, .(N = N[1]), by =list(linkId.from, linkId.to, timeBins) ]
A[, N.left := 0 ]
setkey(A, linkId.from, linkId.to, timeBins)
bank = c()
unique.trips =db[, min(N>1)  , trip][V1 ==1][, trip]
repeat{
n = length(unique.trips)
car = unique.trips[sample.int(n,1)]
k = db[trip==car, .(linkId.from, linkId.to, timeBins)]
if(A[k, all(N -N.left - 1> 0 )]){
bank = c(bank,car)              ## add the trip
unique.trips = setdiff(unique.trips, bank) ## removing all smapled trips
## updating A
A[k, N.left:= N.left + 1]
## break if number of samples reached
if(length(bank) >=M)
break
}
}
bank
}
#install.packages("devtools")
#devtools::install_github("melmasri/traveltimeHMM")
library(traveltimeHMM)
library(dplyr)
library(tidyr)
library(data.table)
# Loading data
Sumo_data <- read.csv("Quebec_data/Real_data.csv")
Sumo_data$speed <- exp(Sumo_data$logspeed)
# Transforming variables
Sumo_data <- as.data.table(Sumo_data)
Sumo_data$timeBins <- as.character(Sumo_data$timeBins)
# Creating test trips
set.seed(2020)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
# Splitting data into train and test set
test = Sumo_data[trip %in% test.trips.Sumo]
train = Sumo_data[!trip %in% test.trips.Sumo]
# Counting the the number of trips in each set
print(paste0("Number of trips inside the test set: ", test[, 1, trip][, sum(V1)]))
print(paste0("Number of trips inside the train set: ", train[, 1, trip][, sum(V1)]))
print(paste0("Number of trips in total: ", test[, 1, trip][, sum(V1)] + train[, 1, trip][, sum(V1)]))
# Setting up the rules for our dataset
myrules = list(
list(start='6:30', end= '9:00', days = 0:6, tag='MR'),
list(start='15:00', end= '18:00', days = 0:6, tag='ER')
)
mytimebins = c("MR", "ER", "Other")
test_graph <- graph.network(data.train = train, L = 2, data_TimeBins = mytimebins)
ttCLTmodel <- traveltimeCLT(obj.data.train = test_graph$data.train, obj.graph.stat.full = test_graph$graph.stat.full, M = 1000, bin = "MR", rules = myrules)
ttCLTresults <- predict.traveltimeCLT(obj.traveltime = ttCLTmodel, data.test = test , bin = "MR", rules = myrules)
test
predict.traveltimeCLT <- function(obj.traveltime = NULL, obj.graph.stat.full = NULL, data.test = NULL, bin = NULL , rules = NULL){
data.test[, linkId.from := linkId, by = trip]
data.test[, linkId.to := shift(linkId, type = 'lead'), by = trip]
data.test[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
# We take trips from the test set that occured in the morning
samp.test = data.test[, timeBins[1], trip][V1 == bin , trip]
param_zeta<-function(t0, rho,linkfrom, linkto, len, sequence = FALSE){
t0 = as.POSIXlt(t0)
time_bins <- rules2timebins(rules)
tbin = time_bins(t0)
g = obj.graph.stat.full$Graph.stat[linkId.from %in% linkfrom]
t = 0                               # time (mean)
vcumlative = 0                                 # variance
vprev = 1
lenprev = 1
if(sequence){
t.seq = v.seq = numeric(length(len))
}
for(i  in 1:(length(len) - 1)){
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
t = t + len[i]*d$mean
tbin = time_bins(t0 + t)
vcumlative = vcumlative + len[i]^2  * d$sd^2  + 2*rho* len[i]*lenprev * d$sd * vprev
vprev = d$sd
lenprev = len[i]
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
}
## last linkId.to is NA
i = i+1
if(is.na(linkto[i])){
d = g[linkId.from == linkfrom[i] & timeBins == tbin & is.na(linkId.to)]
}else{
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
}
t = t + len[i]*d$mean
vcumlative = vcumlative + len[i]^2 * d$sd^2 + 2* rho * len[i]*lenprev *d$sd *vprev
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
s = sqrt(vcumlative)
if(sequence){
list(tt =t, sd = s, v.seq = sqrt(v.seq), t.seq = t.seq)
}else{
list(tt =t, sd = s)
}}
# We apply the method on the test data
A = data.test[trip %in% samp.test, param_zeta(time[1], obj.traveltime$Rho, linkId.from, linkId.to, length), by = trip]
# We merge to be able to get the observed travel time, the real travel time, and the variance
B = merge(data.test[, .(obstt = sum(tt)), trip], A)
# We get the results using the mean of the residuals v
numerical_res<-function(tt, est, sym.q){
list(
MAREgeo = 100*exp(mean(log(abs(tt - est)/tt))),
RMSE = sqrt(mean((tt - est)^2)),
MAE  = mean(abs(tt - est)),
ME  = mean(tt- est),
MAPE = 100*mean(abs(tt - est)/tt),
emprical.cov = 100*mean(abs(tt-est)<=sym.q),
PI.length = mean(2*sym.q),
PI.rel.length = 100*mean(2*sym.q/tt)
)
}
print("Model estimation using V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975)*obj.traveltime$Variance)]))
# We get the results without using v
print("Model estimation without V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975))]))
}
ttCLTresults <- predict.traveltimeCLT(obj.traveltime = ttCLTmodel, data.test = test , bin = "MR", rules = myrules)
predict.traveltimeCLT <- function(obj.traveltime = NULL, obj.graph.stat.full = NULL, data.test = NULL, bin = NULL , rules = NULL){
data.test[, linkId.from := linkId, by = trip]
data.test[, linkId.to := shift(linkId, type = 'lead'), by = trip]
data.test[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
# We take trips from the test set that occured in the morning
samp.test = data.test[, timeBins[1], trip][V1 == bin , trip]
param_zeta<-function(t0, rho,linkfrom, linkto, len, sequence = FALSE){
t0 = as.POSIXlt(t0)
time_bins <- rules2timebins(rules)
tbin = time_bins(t0)
g = obj.graph.stat.full$Graph.stat[linkId.from %in% linkfrom]
t = 0                               # time (mean)
vcumlative = 0                                 # variance
vprev = 1
lenprev = 1
if(sequence){
t.seq = v.seq = numeric(length(len))
}
for(i  in 1:(length(len) - 1)){
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
t = t + len[i]*d$mean
tbin = time_bins(t0 + t)
vcumlative = vcumlative + len[i]^2  * d$sd^2  + 2*rho* len[i]*lenprev * d$sd * vprev
vprev = d$sd
lenprev = len[i]
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
}
## last linkId.to is NA
i = i+1
if(is.na(linkto[i])){
d = g[linkId.from == linkfrom[i] & timeBins == tbin & is.na(linkId.to)]
}else{
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
}
t = t + len[i]*d$mean
vcumlative = vcumlative + len[i]^2 * d$sd^2 + 2* rho * len[i]*lenprev *d$sd *vprev
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
s = sqrt(vcumlative)
if(sequence){
list(tt =t, sd = s, v.seq = sqrt(v.seq), t.seq = t.seq)
}else{
list(tt =t, sd = s)
}}
# We apply the method on the test data
A = data.test[trip %in% samp.test, param_zeta(time[1], obj.traveltime$rho, linkId.from, linkId.to, length), by = trip]
# We merge to be able to get the observed travel time, the real travel time, and the variance
B = merge(data.test[, .(obstt = sum(tt)), trip], A)
# We get the results using the mean of the residuals v
numerical_res<-function(tt, est, sym.q){
list(
MAREgeo = 100*exp(mean(log(abs(tt - est)/tt))),
RMSE = sqrt(mean((tt - est)^2)),
MAE  = mean(abs(tt - est)),
ME  = mean(tt- est),
MAPE = 100*mean(abs(tt - est)/tt),
emprical.cov = 100*mean(abs(tt-est)<=sym.q),
PI.length = mean(2*sym.q),
PI.rel.length = 100*mean(2*sym.q/tt)
)
}
print("Model estimation using V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975)*obj.traveltime$variance)]))
# We get the results without using v
print("Model estimation without V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975))]))
}
ttCLTresults <- predict.traveltimeCLT(obj.traveltime = ttCLTmodel, data.test = test , bin = "MR", rules = myrules)
ttCLTresults <- predict.traveltimeCLT(obj.traveltime = ttCLTmodel, obj.graph.stat.full = test_graph$graph.stat.full, data.test = test, bin = "MR", rules = myrules)
ttCLTresults <- predict.traveltimeCLT(obj.traveltime = ttCLTmodel, obj.graph.stat.full = test_graph$graph.stat.full, data.test = test, bin = "MR", rules = myrules)
data.test = test
data.test[, linkId.from := linkId, by = trip]
data.test[, linkId.to := shift(linkId, type = 'lead'), by = trip]
data.test[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
# We take trips from the test set that occured in the morning
samp.test = data.test[, timeBins[1], trip][V1 == bin , trip]
bin = "MR"
# We take trips from the test set that occured in the morning
samp.test = data.test[, timeBins[1], trip][V1 == bin , trip]
param_zeta<-function(t0, rho,linkfrom, linkto, len, sequence = FALSE){
t0 = as.POSIXlt(t0)
time_bins <- rules2timebins(rules)
tbin = time_bins(t0)
g = obj.graph.stat.full$Graph.stat[linkId.from %in% linkfrom]
t = 0                               # time (mean)
vcumlative = 0                                 # variance
vprev = 1
lenprev = 1
if(sequence){
t.seq = v.seq = numeric(length(len))
}
for(i  in 1:(length(len) - 1)){
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
t = t + len[i]*d$mean
tbin = time_bins(t0 + t)
vcumlative = vcumlative + len[i]^2  * d$sd^2  + 2*rho* len[i]*lenprev * d$sd * vprev
vprev = d$sd
lenprev = len[i]
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
}
## last linkId.to is NA
i = i+1
if(is.na(linkto[i])){
d = g[linkId.from == linkfrom[i] & timeBins == tbin & is.na(linkId.to)]
}else{
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
}
t = t + len[i]*d$mean
vcumlative = vcumlative + len[i]^2 * d$sd^2 + 2* rho * len[i]*lenprev *d$sd *vprev
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
s = sqrt(vcumlative)
if(sequence){
list(tt =t, sd = s, v.seq = sqrt(v.seq), t.seq = t.seq)
}else{
list(tt =t, sd = s)
}}
obj.graph.stat.full = test_graph$graph.stat.full
# We apply the method on the test data
A = data.test[trip %in% samp.test, param_zeta(time[1], obj.traveltime$rho, linkId.from, linkId.to, length), by = trip]
rules = myrules
# We apply the method on the test data
A = data.test[trip %in% samp.test, param_zeta(time[1], obj.traveltime$rho, linkId.from, linkId.to, length), by = trip]
obj.graph.stat.full
data.test
predict.traveltimeCLT <- function(obj.traveltime = NULL, obj.graph.stat.full = NULL, data.test = NULL, bin = NULL , rules = NULL){
data.test[, linkId.from := linkId, by = trip]
data.test[, linkId.to := shift(linkId, type = 'lead'), by = trip]
data.test[, N:=.N, by =list(linkId.from, linkId.to, timeBins) ]
# We take trips from the test set that occured in the morning
samp.test = data.test[, timeBins[1], trip][V1 == bin , trip]
param_zeta<-function(t0, rho,linkfrom, linkto, len, sequence = FALSE){
t0 = as.POSIXlt(t0)
time_bins <- rules2timebins(rules)
tbin = time_bins(t0)
g = obj.graph.stat.full[linkId.from %in% linkfrom]
t = 0                               # time (mean)
vcumlative = 0                                 # variance
vprev = 1
lenprev = 1
if(sequence){
t.seq = v.seq = numeric(length(len))
}
for(i  in 1:(length(len) - 1)){
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
t = t + len[i]*d$mean
tbin = time_bins(t0 + t)
vcumlative = vcumlative + len[i]^2  * d$sd^2  + 2*rho* len[i]*lenprev * d$sd * vprev
vprev = d$sd
lenprev = len[i]
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
}
## last linkId.to is NA
i = i+1
if(is.na(linkto[i])){
d = g[linkId.from == linkfrom[i] & timeBins == tbin & is.na(linkId.to)]
}else{
d = g[linkId.from == linkfrom[i] & linkId.to == linkto[i] & timeBins == tbin]
}
t = t + len[i]*d$mean
vcumlative = vcumlative + len[i]^2 * d$sd^2 + 2* rho * len[i]*lenprev *d$sd *vprev
if(sequence){
v.seq[i] = vcumlative
t.seq[i] = t
}
s = sqrt(vcumlative)
if(sequence){
list(tt =t, sd = s, v.seq = sqrt(v.seq), t.seq = t.seq)
}else{
list(tt =t, sd = s)
}}
# We apply the method on the test data
A = data.test[trip %in% samp.test, param_zeta(time[1], obj.traveltime$rho, linkId.from, linkId.to, length), by = trip]
# We merge to be able to get the observed travel time, the real travel time, and the variance
B = merge(data.test[, .(obstt = sum(tt)), trip], A)
# We get the results using the mean of the residuals v
numerical_res<-function(tt, est, sym.q){
list(
MAREgeo = 100*exp(mean(log(abs(tt - est)/tt))),
RMSE = sqrt(mean((tt - est)^2)),
MAE  = mean(abs(tt - est)),
ME  = mean(tt- est),
MAPE = 100*mean(abs(tt - est)/tt),
emprical.cov = 100*mean(abs(tt-est)<=sym.q),
PI.length = mean(2*sym.q),
PI.rel.length = 100*mean(2*sym.q/tt)
)
}
print("Model estimation using V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975)*obj.traveltime$variance)]))
# We get the results without using v
print("Model estimation without V")
print(t(B[ , numerical_res(obstt, tt, sd *qnorm(0.975))]))
}
ttCLTresults <- predict.traveltimeCLT(obj.traveltime = ttCLTmodel, obj.graph.stat.full = test_graph$graph.stat.full, data.test = test, bin = "MR", rules = myrules)
typeof(mytimebins)
mytimebins = c("MR", "ER", "Other")
typeof(mytimebins)
str(mytimebins)
library(traveltimeCLT)
library(dplyr)
library(tidyr)
library(data.table)
# Loading data
Sumo_data <- read.csv("Quebec_data/Real_data.csv")
Sumo_data$speed <- exp(Sumo_data$logspeed)
# Transforming variables
Sumo_data <- as.data.table(Sumo_data)
Sumo_data$timeBins <- as.character(Sumo_data$timeBins)
# Creating test trips
set.seed(2020)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
# Splitting data into train and test set
test = Sumo_data[trip %in% test.trips.Sumo]
train = Sumo_data[!trip %in% test.trips.Sumo]
# Counting the the number of trips in each set
print(paste0("Number of trips inside the test set: ", test[, 1, trip][, sum(V1)]))
print(paste0("Number of trips inside the train set: ", train[, 1, trip][, sum(V1)]))
print(paste0("Number of trips in total: ", test[, 1, trip][, sum(V1)] + train[, 1, trip][, sum(V1)]))
# Loading data
Sumo_data <- read.csv("Quebec_data/Real_data.csv")
Sumo_data$speed <- exp(Sumo_data$logspeed)
# Transforming variables
Sumo_data <- as.data.table(Sumo_data)
Sumo_data$timeBins <- as.character(Sumo_data$timeBins)
# Creating test trips
set.seed(2020)
test.trips.Sumo <- create_test_trips(M = 2000, Sumo_data, min.n = 1)
# Splitting data into train and test set
test = Sumo_data[trip %in% test.trips.Sumo]
train = Sumo_data[!trip %in% test.trips.Sumo]
# Counting the the number of trips in each set
print(paste0("Number of trips inside the test set: ", test[, 1, trip][, sum(V1)]))
print(paste0("Number of trips inside the train set: ", train[, 1, trip][, sum(V1)]))
print(paste0("Number of trips in total: ", test[, 1, trip][, sum(V1)] + train[, 1, trip][, sum(V1)]))
# Setting up the rules for our dataset
myrules = list(
list(start='6:30', end= '9:00', days = 0:6, tag='MR'),
list(start='15:00', end= '18:00', days = 0:6, tag='ER')
)
mytimebins = c("MR", "ER", "Other")
graph <- graph.traveltimeCLT(data.train = train, L = 2, data_TimeBins = mytimebins)
graph <- graph.traveltimeCLT(data.train = train, L = 2, data.timebins = mytimebins)
ttCLTmodel <- traveltimeCLT(obj.data.train = graph$data.train, obj.graph.stat.full = test_graph$graph.stat.full, M = 1000, bin = "MR", rules = myrules)
ttCLTmodel <- traveltimeCLT(obj.data.train = graph$data.train, obj.graph.stat.full = graph$graph.stat.full, M = 1000, bin = "MR", rules = myrules)
ttCLTresults <- predict.traveltimeCLT(obj.traveltime = ttCLTmodel, obj.graph.stat.full = graph$graph.stat.full, data.test = test, bin = "MR", rules = myrules)
library(traveltimeCLT)
library(traveltimeCLT)
?graph.traveltimeCLT
remove.packages(traveltimeCLT())
remove.packages(traveltimeCLT)
library()
remove.packages("traveltimeCLT")
library(traveltimeCLT)
devtools::install_github("klutometis/roxygen", force=TRUE)
library(roxygen2)
remove.packages("roxygen2")
devtools::install_github("klutometis/roxygen", force=TRUE)
devtools::install_github("klutometis/roxygen")
devtools::install_github("klutometis/roxygen")
install.packages("ps")
install.packages("ps")
devtools::install_github("klutometis/roxygen")
devtools::install_github("klutometis/roxygen")
install.packages("stringi")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
devtools::install_github("klutometis/roxygen")
devtools::install_github("klutometis/roxygen")
devtools::install_github("klutometis/roxygen")
devtools::install_github("klutometis/roxygen", dependencies = TRUE)
devtools::install_github("klutometis/roxygen")
devtools::install_github("klutometis/roxygen")
.libPaths()
devtools::install_github("klutometis/roxygen")
#install.packages("devtools")
#devtools::install_github("melmasri/traveltimeHMM")
library(traveltimeHMM)
library(dplyr)
install.packages("tidyr")
library(tidyr)
library(data.table)
library("C:/Desktop/traveltimeCLT")
library("myRPackage", lib.loc="C:\Users\adrie\Desktop")
library("myRPackage", lib.loc="C:/Users/adrie/Desktop")
library("traveltimeCLT", lib.loc="C:/Users/adrie/Desktop")
